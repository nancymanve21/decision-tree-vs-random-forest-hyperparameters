# Decision Tree vs Random Forest â€“ Hyperparameter Analysis

## Overview
This project focuses on building and comparing two popular supervised machine learning algorithms: **Decision Tree** and **Random Forest**. The goal is to understand how different hyperparameters affect model performance and generalization.

The notebook walks through data preprocessing, model training, evaluation, and comparison in a structured and beginner-friendly manner.

---

## Objectives
- Understand the working of Decision Tree and Random Forest models
- Explore key hyperparameters and their impact on model performance
- Compare single-tree vs ensemble-based approaches
- Evaluate models using standard performance metrics

---

## Models Used
- Decision Tree Classifier
- Random Forest Classifier

---

## Key Concepts Covered
- Hyperparameters vs model parameters
- Overfitting and underfitting
- Effect of tree depth and number of estimators
- Model evaluation and comparison

---

## Technologies Used
- Python
- Pandas
- NumPy
- Scikit-learn
- Jupyter Notebook

---

## Workflow
1. Data loading and preprocessing
2. Model training with default parameters
3. Hyperparameter tuning
4. Model evaluation and comparison
5. Result interpretation

---

## Results
The project demonstrates how Random Forest generally provides better performance and robustness compared to a single Decision Tree by reducing overfitting through ensemble learning.

---

## Learning Outcome
This project strengthened my understanding of supervised learning models, hyperparameter tuning, and model evaluation, which are essential skills for data analyst and entry-level machine learning roles.

---

## Author
Nancy Manve
